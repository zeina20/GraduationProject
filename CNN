
from google.colab import drive
drive.mount('/content/gdrive')
%matplotlib inline
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import math
import copy
import numpy as np
!pip install keras_vggface
!pip install keras_applications
!pip install keras.engine.topology
!pip install np_utils
!pip install tensorflow
from keras.utils.layer_utils import get_source_inputs
from keras.utils import get_source_inputs
from keras.utils.layer_utils import get_source_inputs
from tensorflow import keras
#import tensorflow as tf
#from tensorflow.keras import layers
#from keras import utils as np_utils
#import tensorflow.keras
from keras.utils.np_utils import to_categorical
#from tensorflow.keras.layers import Layer, InputSpec
from tensorflow.python.keras.layers import Layer, InputSpec
#from keras.models import Sequential, Model
#from keras.engine.topology import get_source_inputs
#from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape
from keras_vggface.vggface import VGGFace
from keras_vggface import utils
from keras.preprocessing import image
from sklearn.datasets import load_files       
from keras.utils import np_utils
import numpy as np
from glob import glob
import pandas as pd
import cv2
import scipy.misc
import matplotlib.pyplot as plt
%matplotlib inline

# define function to load train, test, and validation datasets
def load_dataset(path):
    """
    Loads the images from path.
    
    Args
    ----------
    path : String
        Holds the path of the dataset

    Returns
    -------
    Array
        Two numpy arrays that holds the images and the targets.
    """
    data = load_files(path)
    face_files = np.array(data['filenames'])
    face_targets = np_utils.to_categorical(np.array(data['target']), 2)
    return face_files, face_targets

# load train, test, and validation datasets
train_files, train_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/train')
valid_files, valid_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/valid')
test_files, test_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/test')


# load list of dog names
face_names = [item[20:-1] for item in sorted(glob("/content/gdrive/MyDrive/DATASET/facesResNet/train/*/"))]

# print statistics about the dataset
print('There are %d total face names.' % len(face_names))
print('There are %s total face images.\n' % len(np.hstack([train_files, valid_files, test_files])))
print('There are %d training face images.' % len(train_files))
print('There are %d validation face images.' % len(valid_files))
print('There are %d test face images.'% len(test_files))
from PIL import Image
import cv2  
import glob
import time
from google.colab.patches import cv2_imshow  
img_number=0
# Load the cascade  
face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
#file path
path='/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/videos/train_sample_videos/'  
all_videos=glob.glob(path + "*mp4")
li=[]
counter=0
for video in all_videos:
  # To capture video from existing video.  
  cap = cv2.VideoCapture(video)  
  counter=counter+1
  print(counter)
  #while True:  
    # Read the frame 
  _, img = cap.read()     
  _, img = cap.read()
  #cv2_imshow(img)  
    # Convert to grayscale  
    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  
 
    # Detect the faces 
     faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=2)  
  wmax=0
  hmax=0
  ImageFolder ='/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train'
    # Draw the rectangle around each face  
  for (x, y, w, h) in faces: 
    if w>wmax and h>hmax:
      wmax=w
      hmax=h
  #print(wmax)
  #print(hmax)
  for (x, y, w, h) in faces: 
    img_number=img_number+1
    if w == wmax and h==hmax : 
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 1)  
        crop_img = img[y:y+h, x:x+w]
        li.append(crop_img)
        cv2.imwrite("/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train/image_"+str(img_number)+".jpg",crop_img)
        #crop_img = crop_img.save("/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/trainimage_"+str(img_number)+".jpg")
        #test=cv2.imwrite('/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train/image_{i}.png',crop_img)
        #print(test)
        
    # Display  
        cv2_imshow(crop_img) 
        #img.save('/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train'+ crop_img , 'JPEG')
    # Stop if escape key is pressed  
  k = cv2.waitKey(1000) & 0xff  
  if k==27:  
        break  
         
# Release the VideoCapture object  
  cap.release()
  
  def performance_viz(history, xc_length):
    """
    Visualizes training history.
    
    Args
    ----------
    history : Keras object
        Holds the training history

    Returns
    -------
    Empty.
    """
    train_loss = history_aug.history['loss']
    val_loss = history_aug.history['val_loss']
    train_acc = history_aug.history['acc']
    val_acc = history_aug.history['val_acc']
    xc = range(xc_length)

    # Visualize Train vs Validation loss
    plt.figure(1,figsize=(7,5))
    plt.plot(xc,train_loss)
    plt.plot(xc,val_loss)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Train_loss vs Val_loss')
    plt.grid(True)
    plt.legend(['train','val'])
    print (plt.style.available)
    plt.style.use(['classic'])
    plt.show()
    # Visualize Train vs Validation Accuracy
    plt.figure(2,figsize=(7,5))
    plt.plot(xc,train_acc)
    plt.plot(xc,val_acc)
    plt.xlabel('Epochs')
    plt.ylabel('Acc')
    plt.title('Train Acc vs Val Acc')
    plt.grid(True)
    plt.legend(['Train','Val'],loc=4)
    plt.style.use(['classic'])
    plt.show()
    
    # Loads the weights and Evaluates the model's performance
def load_weights(model,file_name, test, test_targets):
    """
    Load the best weights saved from during training the proposed CNN architecture and evaluates the model's performance.
    
    Args
    ----------
    model : Keras object
        Holds the proposed CNN architecture.
    
    test : Numpy array
        Holds the test images.
    
    test_targets : Numpy Array
        Holds the images labels in a string format.
    
    Returns
    -------
    Empty.
    """
    model.load_weights('saved_models/' + file_name) # Load weights

    score = model.evaluate(test, test_targets, verbose=0)
    print('\n', 'Test accuracy:', score[1])
    
    import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Load original image
img_1 = mpimg.imread(train_files[0])

# Load fake image
img_2 = mpimg.imread(train_files[2])

# Print a subplot
plt.figure(1)
plt.subplot(211)
plt.imshow(img_1)

plt.subplot(212)
plt.imshow(img_2)
plt.show()

from keras.preprocessing import image                  
from tqdm import tqdm

def path_to_tensor(img_path):
    """
    Creates tensor of a single image to be consumed by the CNN architecture.
    
    Args
    ----------
    img_path : Numpy Array
        Holds the images paths.
    
    Returns
    -------
    Tensor : Tensorflow object.
        Holds the converted image.
    """
    # loads RGB image as PIL.Image.Image type
    img = image.load_img(img_path, target_size=(224, 224))
    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)
    x = image.img_to_array(img)
    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor
    return np.expand_dims(x, axis=0)

def paths_to_tensor(img_paths):
    """
    Creates tensors of images to be consumed by the CNN architecture.
    
    Args
    ----------
    img_path : Numpy Array
        Holds the images paths.
    
    Returns
    -------
    list_of_tensors : Tensorflow object.
        Holds the converted images.
    """
    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]
    return np.vstack(list_of_tensors)
