
from google.colab import drive
drive.mount('/content/gdrive')
%matplotlib inline
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import math
import copy
import numpy as np
!pip install keras_vggface
!pip install keras_applications
!pip install keras.engine.topology
!pip install np_utils
!pip install tensorflow
from keras.utils.layer_utils import get_source_inputs
from keras.utils import get_source_inputs
from keras.utils.layer_utils import get_source_inputs
from tensorflow import keras
#import tensorflow as tf
#from tensorflow.keras import layers
#from keras import utils as np_utils
#import tensorflow.keras
from keras.utils.np_utils import to_categorical
#from tensorflow.keras.layers import Layer, InputSpec
from tensorflow.python.keras.layers import Layer, InputSpec
#from keras.models import Sequential, Model
#from keras.engine.topology import get_source_inputs
#from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape
from keras_vggface.vggface import VGGFace
from keras_vggface import utils
from keras.preprocessing import image
from sklearn.datasets import load_files       
from keras.utils import np_utils
import numpy as np
from glob import glob
import pandas as pd
import cv2
import scipy.misc
import matplotlib.pyplot as plt
%matplotlib inline

# define function to load train, test, and validation datasets
def load_dataset(path):
    """
    Loads the images from path.
    
    Args
    ----------
    path : String
        Holds the path of the dataset

    Returns
    -------
    Array
        Two numpy arrays that holds the images and the targets.
    """
    data = load_files(path)
    face_files = np.array(data['filenames'])
    face_targets = np_utils.to_categorical(np.array(data['target']), 2)
    return face_files, face_targets

# load train, test, and validation datasets
train_files, train_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/train')
valid_files, valid_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/valid')
test_files, test_targets = load_dataset('/content/gdrive/MyDrive/DATASET/facesResNet/test')


# load list of dog names
face_names = [item[20:-1] for item in sorted(glob("/content/gdrive/MyDrive/DATASET/facesResNet/train/*/"))]

# print statistics about the dataset
print('There are %d total face names.' % len(face_names))
print('There are %s total face images.\n' % len(np.hstack([train_files, valid_files, test_files])))
print('There are %d training face images.' % len(train_files))
print('There are %d validation face images.' % len(valid_files))
print('There are %d test face images.'% len(test_files))
from PIL import Image
import cv2  
import glob
import time
from google.colab.patches import cv2_imshow  
img_number=0
# Load the cascade  
face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
#file path
path='/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/videos/train_sample_videos/'  
all_videos=glob.glob(path + "*mp4")
li=[]
counter=0
for video in all_videos:
  # To capture video from existing video.  
  cap = cv2.VideoCapture(video)  
  counter=counter+1
  print(counter)
  #while True:  
    # Read the frame 
  _, img = cap.read()     
  _, img = cap.read()
  #cv2_imshow(img)  
    # Convert to grayscale  
    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  
 
    # Detect the faces 
     faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=2)  
  wmax=0
  hmax=0
  ImageFolder ='/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train'
    # Draw the rectangle around each face  
  for (x, y, w, h) in faces: 
    if w>wmax and h>hmax:
      wmax=w
      hmax=h
  #print(wmax)
  #print(hmax)
  for (x, y, w, h) in faces: 
    img_number=img_number+1
    if w == wmax and h==hmax : 
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 1)  
        crop_img = img[y:y+h, x:x+w]
        li.append(crop_img)
        cv2.imwrite("/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train/image_"+str(img_number)+".jpg",crop_img)
        #crop_img = crop_img.save("/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/trainimage_"+str(img_number)+".jpg")
        #test=cv2.imwrite('/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train/image_{i}.png',crop_img)
        #print(test)
        
    # Display  
        cv2_imshow(crop_img) 
        #img.save('/content/gdrive/MyDrive/Fake-Face-Detection-DeepFakes-CNN-master/faces/train'+ crop_img , 'JPEG')
    # Stop if escape key is pressed  
  k = cv2.waitKey(1000) & 0xff  
  if k==27:  
        break  
         
# Release the VideoCapture object  
  cap.release()
